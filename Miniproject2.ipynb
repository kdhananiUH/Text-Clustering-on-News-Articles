{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>abortion</th>\n",
       "      <th>absolute</th>\n",
       "      <th>abstain</th>\n",
       "      <th>abu</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zogby</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3430 rows × 1545 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abandon  abc  ability  abortion  absolute  abstain  abu  abuse  accept  \\\n",
       "0           0    0        0         0         0        0    0      0       0   \n",
       "1           0    0        0         0         0        0    0      0       0   \n",
       "2           0    0        0         0         0        1    0      0       0   \n",
       "3           0    0        0         0         0        0    0      0       0   \n",
       "4           0    0        0         0         0        0    0      0       0   \n",
       "...       ...  ...      ...       ...       ...      ...  ...    ...     ...   \n",
       "3425        0    0        0         0         0        0    0      0       0   \n",
       "3426        0    0        0         0         0        0    0      0       0   \n",
       "3427        0    0        0         0         0        0    0      0       0   \n",
       "3428        0    0        0         0         0        0    0      0       0   \n",
       "3429        0    0        0         0         0        0    0      0       0   \n",
       "\n",
       "      access  ...  yeah  year  yesterday  york  youll  young  youre  youve  \\\n",
       "0          0  ...     0     0          0     0      0      0      0      0   \n",
       "1          0  ...     0     0          0     0      0      0      0      0   \n",
       "2          0  ...     0     0          0     0      0      0      0      0   \n",
       "3          0  ...     0     0          2     0      0      1      0      0   \n",
       "4          0  ...     0     1          1     0      0      1      0      0   \n",
       "...      ...  ...   ...   ...        ...   ...    ...    ...    ...    ...   \n",
       "3425       0  ...     0     0          0     0      0      0      0      0   \n",
       "3426       0  ...     0     0          0     0      0      0      0      0   \n",
       "3427       0  ...     0     0          0     1      0      0      0      0   \n",
       "3428       0  ...     0     0          0     0      0      0      0      0   \n",
       "3429       0  ...     0     0          0     0      0      0      0      0   \n",
       "\n",
       "      zogby  zone  \n",
       "0         0     1  \n",
       "1         0     0  \n",
       "2         0     0  \n",
       "3         0     0  \n",
       "4         0     0  \n",
       "...     ...   ...  \n",
       "3425      0     0  \n",
       "3426      0     0  \n",
       "3427      0     0  \n",
       "3428      0     0  \n",
       "3429      0     0  \n",
       "\n",
       "[3430 rows x 1545 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df  = pd.read_csv('dailykos.csv')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let’s start by building a hierarchical clustering model. First, read the data set. Then, compute the Euclidian distances. You should cluster on all of the features.\n",
    "\n",
    "Plot the dendrogram.\n",
    "\n",
    "Creating the distances will probably take you a while. Why? Explain.\n",
    "\n",
    "\n",
    "- Computing the distance between all data points can be computationally expensive and time consuming. Euclidean distance computation involves subtracting each feature value of one point from the corresponding feature value of the other point, squaring the differences, summing the squared differences across all features, and taking the square root of the sum. The time required to compute the distances depends on the number of data points and number of features. As the number of data points increases, the number of distance calculations required increases exponentially, making the computation time grow rapidly. Additionally, if the dataset has many features, the Euclidean distance calculation for each pair of data points can become more computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaush\\anaconda3\\lib\\site-packages\\scipy\\cluster\\hierarchy.py:834: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  return linkage(y, method='ward', metric='euclidean')\n",
      "C:\\Users\\kaush\\AppData\\Local\\Temp\\ipykernel_14696\\4275688181.py:15: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  linkage_matrix = linkage(distances, method='ward')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# Compute Euclidean distances\n",
    "distances = euclidean_distances(df)\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None, linkage='ward', affinity='euclidean')\n",
    "model.fit(distances)\n",
    "\n",
    "# Plot dendrogram\n",
    "linkage_matrix = linkage(distances, method='ward')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Documents')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(linkage_matrix)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (10 points) In this problem, we are trying to cluster news articles or blog posts into groups. This can be used to show readers categories to choose from when trying to decide what to read. Just thinking about this application, what are good choices for the number of clusters? Explain your thinking."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several methods to find the ideal number of clusters, such as elbow method, silhouette statistic, Gap statistics etc. We have explained elbow method and silhouette coefficient method below.\n",
    "\n",
    "1. The elbow method: This method involves plotting the within-cluster sum of squares (WSS) for different values of the k (number of clusters). The elbow point is the value of k where the WSS starts to level off. This is often used as a heuristic for the ideal number of clusters.\n",
    "\n",
    "2. The silhouette coefficient: This method measures the average similarity of a data point to the other data points in its cluster, compared to the average similarity of the data point to the data points in other clusters. The silhouette coefficient is typically plotted for different values of k. The value of k that corresponds to the highest average silhouette coefficient is often used as the ideal number of clusters.\n",
    "Thus, a good range for the number of clusters is 5 to 10, which offers a good balance of granularity and interpretability. It is important to note that there is no single \"correct\" method for determining the ideal number of clusters. The best method to use will depend on the specific dataset and the desired results.\n",
    "\n",
    "- Thus, a good range for the number of clusters is 5 to 10, which offers a good balance of granularity and interpretability. It is important to note that there is no single \"correct\" method for determining the ideal number of clusters. The best method to use will depend on the specific dataset and the desired results.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Let’s pick 7 clusters and answer the following questions:\n",
    "\n",
    "How many observations are in cluster 3?\n",
    "Which cluster has the most observations?\n",
    "Which cluster has the fewest observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in cluster 3: 1761\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Cluster the data into 7 clusters using hierarchical clustering\n",
    "model = AgglomerativeClustering(n_clusters=7, linkage='ward',affinity='euclidean')\n",
    "clusters = model.fit_predict(df)\n",
    "#df['clusters'] = clusters\n",
    "\n",
    "# How many observations are in cluster 3?\n",
    "print(f\"Number of observations in cluster 3: {sum(clusters == 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations in Cluster 3: 1761\n",
      "Number of Observations in Cluster 2: 167\n",
      "Number of Observations in Cluster 4: 324\n",
      "Number of Observations in Cluster 1: 803\n",
      "Number of Observations in Cluster 7: 50\n",
      "Number of Observations in Cluster 5: 270\n",
      "Number of Observations in Cluster 6: 55\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the number of times each cluster label appears in the `clusters` array\n",
    "cluster_counts = Counter(clusters)\n",
    "\n",
    "# Print the number of observations in each cluster\n",
    "for cluster, count in cluster_counts.items():\n",
    "    print(f\"Number of Observations in Cluster {cluster+1}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of observations: 1761 in Cluster 3\n",
      "Minimum number of observations: 50 in cluster 7\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum and minimum number of observations\n",
    "max_observations = max(cluster_counts.values())\n",
    "min_observations = min(cluster_counts.values())\n",
    "\n",
    "# Print the maximum and minimum number of observations\n",
    "print(f\"Maximum number of observations: {max_observations} in Cluster 3\")\n",
    "print(f\"Minimum number of observations: {min_observations} in cluster 7\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Instead of looking at the average value in each variable individually, we’ll just look at the top 6 words in each cluster.\n",
    "\n",
    "Compute the mean frequency values of each of the words in cluster 1, and then output the 6 words that occur the most frequently.\n",
    "\n",
    "What is the most frequent word in this cluster, in terms of average value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 6 words in cluster 1:\n",
      "poll          2.429639\n",
      "kerry         2.012453\n",
      "bush          1.922790\n",
      "democrat      1.823163\n",
      "republican    1.328767\n",
      "elect         1.165629\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Find the top 6 words with the highest mean frequency in cluster 1\n",
    "cluster1 = df[clusters == 0]  # filter out cluster 1 data\n",
    "mean_freq = cluster1.mean()  # compute the mean frequency of each word in cluster 1\n",
    "top6_words = mean_freq.nlargest(6)  # find the top 6 words with the highest mean frequency\n",
    "print(f\"Top 6 words in cluster 1:\\n{top6_words}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the frequenct of top 100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poll          2.429639\n",
       "kerry         2.012453\n",
       "bush          1.922790\n",
       "democrat      1.823163\n",
       "republican    1.328767\n",
       "                ...   \n",
       "ballot        0.174346\n",
       "place         0.174346\n",
       "florida       0.170610\n",
       "register      0.170610\n",
       "start         0.170610\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top100_words = mean_freq.nlargest(100)  # find the top 6 words with the highest mean frequency\n",
    "top100_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent word in cluster 1 is poll\n"
     ]
    }
   ],
   "source": [
    "#What is the most frequent word in this cluster, in terms of average value?\n",
    "\n",
    "print('Most frequent word in cluster 1 is poll')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (10 points) Now repeat the command given in the previous problem for each of the other clusters, and answer the following questions.\n",
    "\n",
    "Which cluster could best be described as the cluster related to the Iraq war?\n",
    "In 2004, one of the candidates for the Democratic nomination for the President of the United States was Howard Dean, John Kerry was the candidate who won the democratic nomination, and John Edwards with the running mate of John Kerry (the Vice President nominee). Given this information, which cluster best corresponds to the democratic party?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 6 words in cluster 1:\n",
      "poll          2.429639\n",
      "kerry         2.012453\n",
      "bush          1.922790\n",
      "democrat      1.823163\n",
      "republican    1.328767\n",
      "elect         1.165629\n",
      "dtype: float64\n",
      "\n",
      "Top 6 words in cluster 2:\n",
      "kerry       8.101796\n",
      "bush        7.574850\n",
      "campaign    1.862275\n",
      "poll        1.736527\n",
      "presided    1.616766\n",
      "democrat    1.389222\n",
      "dtype: float64\n",
      "\n",
      "Top 6 words in cluster 3:\n",
      "bush          1.546281\n",
      "democrat      0.659852\n",
      "kerry         0.607609\n",
      "state         0.542873\n",
      "presided      0.526973\n",
      "republican    0.519591\n",
      "dtype: float64\n",
      "\n",
      "Top 6 words in cluster 4:\n",
      "november     10.376543\n",
      "poll          4.851852\n",
      "vote          4.376543\n",
      "challenge     4.104938\n",
      "bush          2.858025\n",
      "democrat      2.858025\n",
      "dtype: float64\n",
      "\n",
      "Top 6 words in cluster 5:\n",
      "bush              4.777778\n",
      "iraq              3.425926\n",
      "war               2.470370\n",
      "administration    2.225926\n",
      "american          1.633333\n",
      "presided          1.488889\n",
      "dtype: float64\n",
      "\n",
      "Top 6 words in cluster 6:\n",
      "dean         12.309091\n",
      "kerry         5.345455\n",
      "democrat      3.545455\n",
      "edward        2.818182\n",
      "candidate     2.727273\n",
      "gephardt      2.672727\n",
      "dtype: float64\n",
      "\n",
      "Top 6 words in cluster 7:\n",
      "democrat      12.38\n",
      "parties        6.34\n",
      "state          5.74\n",
      "republican     5.64\n",
      "senate         3.30\n",
      "seat           3.14\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Find the top 6 words with the highest mean frequency for each cluster\n",
    "for i in range(7):\n",
    "    cluster = df[clusters == i]\n",
    "    mean_freq = cluster.mean()\n",
    "    top6_words = mean_freq.nlargest(6)\n",
    "    print(f\"\\nTop 6 words in cluster {i+1}:\\n{top6_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 5 corresponds to the Iraq War.\n"
     ]
    }
   ],
   "source": [
    "# Which cluster corresponds to the Iraq War?\n",
    "\n",
    "print(\"Cluster 5 corresponds to the Iraq War.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 6 corresponds to the Democratic party.\n"
     ]
    }
   ],
   "source": [
    "# Which cluster corresponds to the Democratic party?\n",
    "\n",
    "print(\"Cluster 6 corresponds to the Democratic party.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (10 points) Now, run k-means clustering, setting the random state to 1000. Again, pick the number of clusters equal to 7.\n",
    "\n",
    "Subset your data into the 7 clusters (7 new datasets) by using the \"cluster\" variable of your kmeans output.\n",
    "\n",
    "How many observations are in Cluster 3?\n",
    "Which cluster has the most observations?\n",
    "Which cluster has the fewest number of observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in Cluster 3: 330\n",
      "Cluster with the most observations: Cluster 2\n",
      "Cluster with the fewest observations: Cluster 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "df  = pd.read_csv('dailykos.csv')\n",
    "\n",
    "# Computing k-means clustering of 7 clusters and a random_state set to 1000\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=1000).fit(df)\n",
    "\n",
    "# Assigning the cluster labels to the kmean cluster frame\n",
    "kmean_cluster = kmeans.labels_\n",
    "\n",
    "# Converting the Numpy ndarray to a Pandas Series\n",
    "kmean_cluster = pd.Series(kmean_cluster)\n",
    "\n",
    "# Counting the number of observations in each cluster\n",
    "cluster_counts1 = kmean_cluster.value_counts()\n",
    "\n",
    "\n",
    "print(f\"Number of observations in Cluster 3: {cluster_counts1.loc[2]}\")\n",
    "print(f\"Cluster with the most observations: Cluster {cluster_counts1.idxmax()+1}\")\n",
    "print(f\"Cluster with the fewest observations: Cluster {cluster_counts1.idxmin()+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations in Cluster 2: 1937\n",
      "Number of Observations in Cluster 4: 368\n",
      "Number of Observations in Cluster 1: 339\n",
      "Number of Observations in Cluster 3: 330\n",
      "Number of Observations in Cluster 7: 264\n",
      "Number of Observations in Cluster 5: 153\n",
      "Number of Observations in Cluster 6: 39\n"
     ]
    }
   ],
   "source": [
    "# Print the number of observations in each cluster\n",
    "for cluster, count in cluster_counts1.items():\n",
    "    print(f\"Number of Observations in Cluster {cluster+1}: {count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (10 points) Now, output the six most frequent words in each cluster, like we did in the previous problem, for each of the k-means clusters.\n",
    "\n",
    "Which k-means cluster best corresponds to the Iraq War?\n",
    "Which k-means cluster best corresponds to the democratic party? (Remember that we are looking for the names of the key democratic party leaders.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 6 words in K-means cluster  1 :\n",
      "democrat      3.064897\n",
      "republican    2.920354\n",
      "state         2.094395\n",
      "elect         1.970501\n",
      "parties       1.793510\n",
      "vote          1.643068\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "Top 6 words in K-means cluster  2 :\n",
      "bush        1.183789\n",
      "kerry       0.799690\n",
      "poll        0.724832\n",
      "democrat    0.631905\n",
      "general     0.505421\n",
      "elect       0.488384\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "Top 6 words in K-means cluster  3 :\n",
      "november     10.369697\n",
      "poll          4.863636\n",
      "vote          4.439394\n",
      "challenge     4.127273\n",
      "bush          3.081818\n",
      "democrat      2.866667\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "Top 6 words in K-means cluster  4 :\n",
      "bush        8.635870\n",
      "kerry       4.934783\n",
      "poll        2.160326\n",
      "presided    1.853261\n",
      "campaign    1.331522\n",
      "democrat    1.312500\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "Top 6 words in K-means cluster  5 :\n",
      "dean        7.725490\n",
      "kerry       5.261438\n",
      "clark       2.993464\n",
      "edward      2.862745\n",
      "democrat    2.633987\n",
      "poll        2.326797\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "Top 6 words in K-means cluster  6 :\n",
      "democrat      15.615385\n",
      "parties        6.589744\n",
      "republican     6.153846\n",
      "state          4.846154\n",
      "senate         4.410256\n",
      "seat           4.282051\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "Top 6 words in K-means cluster  7 :\n",
      "iraq              4.215909\n",
      "bush              3.136364\n",
      "war               3.000000\n",
      "administration    1.863636\n",
      "american          1.772727\n",
      "iraqi             1.643939\n",
      "Name: 6, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute the top 6 words in each kmean clusters\n",
    "\n",
    "clusters1 = pd.DataFrame(df.groupby(kmean_cluster).mean())\n",
    "\n",
    "for i in range(0,7):\n",
    "    print(\"\\nTop 6 words in K-means cluster \", i+1, \":\")\n",
    "    print(clusters1.iloc[i,:].nlargest(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 7 corresponds to the Iraq War.\n"
     ]
    }
   ],
   "source": [
    "# Which k-means cluster corresponds to the Iraq War?\n",
    "print(\"Cluster 7 corresponds to the Iraq War.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 5 corresponds to the Democratic party.\n"
     ]
    }
   ],
   "source": [
    "# Which cluster corresponds to the Democratic party?\n",
    "\n",
    "print(\"Cluster 5 corresponds to the Democratic party.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. (10 points) For the rest of this problem, I’ll ask you to compare how observations were assigned to clusters in the two different methods. You could use the Pandas crosstab function to compare the cluster assignment of hierarchical clustering to the cluster assignment of k-means clustering. :\n",
    "\n",
    "Which Hierarchical Cluster best corresponds to K-Means Cluster 2?\n",
    "Which Hierarchical Cluster best corresponds to K-Means Cluster 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosstab comparison:\n",
      "\n",
      "K-means          0     1    2    3   4   5    6\n",
      "Agglomerative                                  \n",
      "0              240   367    1   97  89   4    5\n",
      "1                2    38    4  114   6   0    3\n",
      "2               75  1509    0   94   4   0   79\n",
      "3                0     0  324    0   0   0    0\n",
      "4               10    23    0   59   0   1  177\n",
      "5                0     0    0    0  54   1    0\n",
      "6               12     0    1    4   0  33    0\n"
     ]
    }
   ],
   "source": [
    "df['clusters'] = clusters\n",
    "\n",
    "# Creating a crosstab comparing the both clustering\n",
    "print(\"Crosstab comparison:\\n\")\n",
    "\n",
    "comparison_crosstab = pd.crosstab(clusters, kmean_cluster, rownames=['Agglomerative'], colnames=['K-means'])\n",
    "print(comparison_crosstab)\n",
    "\n",
    "# Finding the best corresponding agglomerative cluster for each K-means cluster\n",
    "best_corresponding_hierarchical_clusters = comparison_crosstab.idxmax(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hierarchical (Agglomerative) Cluster best corresponding to K-Means Cluster 2: Cluster 3\n",
      "\n",
      " Hierarchical (Agglomerative) Cluster best corresponding to K-Means Cluster 3: Cluster 4 \n"
     ]
    }
   ],
   "source": [
    "# Which Hierarchical Cluster best corresponds to K-Means Cluster 2?\n",
    "print(f\"\\n Hierarchical (Agglomerative) Cluster best corresponding to K-Means Cluster 2: Cluster 3\")\n",
    "\n",
    "# Which Hierarchical Cluster best corresponds to K-Means Cluster 3?\n",
    "print(f\"\\n Hierarchical (Agglomerative) Cluster best corresponding to K-Means Cluster 3: Cluster 4 \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7758e92e9a61d7a3490898707f7eeb937c85e9d1e8d4e877cc6c187218f226d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
